# General

## Encoder:
![](images/general/2025-04-21-13-45-13.png)
### 1. Input Embedding
* Allows us to convert a Sentence into a Vector of 512 Dimensions (Word Vector) using Input IDs
### 2. Positional Encoding
* Represents the position of the word in the sentence using a Vector of 512 Dimensions
* Also used for "teaching" the model sentence structure and grammar

-> add Input Embedding und Positional Encoding together to create the Encoder Input

### 3. Multi Head Attention

## Examples:

### Input Embedding + Positional Encoding:
![](images/general/2025-04-21-13-42-43.png)

## Decoder